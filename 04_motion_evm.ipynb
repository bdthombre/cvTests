{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.signal import butter, lfilter\n",
    "from scipy.ndimage import gaussian_filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Step 1: Temporal Bandpass Filter Definition\n",
    "# def butter_bandpass(lowcut, highcut, fs, order=2):\n",
    "#     nyquist = 0.5 * fs\n",
    "#     low = lowcut / nyquist\n",
    "#     high = highcut / nyquist\n",
    "#     b, a = butter(order, [low, high], btype='band')\n",
    "#     return b, a\n",
    "\n",
    "# def bandpass_filter(data, lowcut, highcut, fs, order=2):\n",
    "#     b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "#     return lfilter(b, a, data, axis=0)\n",
    "\n",
    "# # Step 2: Load Video and Decompose Frames\n",
    "# def load_video(video_path):\n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "#     frames = []\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "#         frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))\n",
    "#     cap.release()\n",
    "#     return np.array(frames)\n",
    "\n",
    "# # Step 3: Build Laplacian Pyramid for Spatial Decomposition\n",
    "# def build_laplacian_pyramid(frame, levels=3):\n",
    "#     pyramid = [frame]\n",
    "#     for _ in range(levels):\n",
    "#         frame = cv2.pyrDown(frame)\n",
    "#         pyramid.append(frame)\n",
    "#     return pyramid\n",
    "\n",
    "# def reconstruct_from_laplacian(pyramid):\n",
    "#     frame = pyramid[-1]\n",
    "#     for level in reversed(pyramid[:-1]):\n",
    "#         frame = cv2.pyrUp(frame)\n",
    "#         frame = cv2.add(frame, level)\n",
    "#     return frame\n",
    "\n",
    "# # Step 4: Eulerian Video Magnification\n",
    "# def eulerian_magnification(video_path, output_path, lowcut, highcut, fs=None, alpha=10, pyramid_levels=3):\n",
    "#     # Load video\n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "#     if not cap.isOpened():\n",
    "#         raise ValueError(\"Error opening video file.\")\n",
    "    \n",
    "#     # Get video properties\n",
    "#     frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#     original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "#     original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "#     if fs is None:\n",
    "#         fs = int(cap.get(cv2.CAP_PROP_FPS))  # Use video frame rate if not provided\n",
    "        \n",
    "#     print(f\"Video Details\\n Frames:{frame_count} Dim: {original_width}x{original_height} Frame Rate: {fs}\")\n",
    "    \n",
    "#     # Read video frames\n",
    "#     frames = []\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "#         gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#         frames.append(gray_frame)\n",
    "#     cap.release()\n",
    "#     frames = np.array(frames)\n",
    "    \n",
    "#     # Process video\n",
    "#     pyramids = []\n",
    "#     for frame in frames:\n",
    "#         pyramids.append(build_laplacian_pyramid(frame, levels=pyramid_levels))\n",
    "    \n",
    "#     filtered_pyramids = [[] for _ in range(pyramid_levels)]\n",
    "#     for level in range(pyramid_levels):\n",
    "#         level_data = np.array([pyramid[level] for pyramid in pyramids])\n",
    "#         filtered_level = bandpass_filter(level_data, lowcut, highcut, fs)\n",
    "#         filtered_pyramids[level] = filtered_level\n",
    "    \n",
    "#     amplified_pyramids = [level * alpha for level in filtered_pyramids]\n",
    "    \n",
    "#     amplified_frames = []\n",
    "#     for i in range(frame_count):\n",
    "#         pyramid = [amplified_pyramids[level][i] if level < len(amplified_pyramids) else pyramids[i][level]\n",
    "#                    for level in range(pyramid_levels)]\n",
    "#         amplified_frame = reconstruct_from_laplacian(pyramid)\n",
    "#         # Resize to original dimensions to ensure compatibility\n",
    "#         amplified_frame = cv2.resize(amplified_frame, (original_width, original_height))\n",
    "#         amplified_frames.append(amplified_frame)\n",
    "    \n",
    "#     # Convert frames to uint8 and clip values\n",
    "#     amplified_frames = np.clip(np.array(amplified_frames), 0, 255).astype(np.uint8)\n",
    "    \n",
    "#     # Write the output video\n",
    "#     fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "#     out = cv2.VideoWriter(output_path, fourcc, fs, (original_width, original_height), isColor=False)\n",
    "#     for frame in amplified_frames:\n",
    "#         out.write(cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR))\n",
    "#     out.release()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Details\n",
      " Frames:301 Dim: 960x544 Frame Rate: 30\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Run Eulerian Video Magnification\n",
    "# video_path = \"tests/baby.mp4\"  # Path to input video\n",
    "# output_path = \"tests/baby_output_video.avi\"  # Path to save the output video\n",
    "# lowcut = 0.4  # Lower bound of the bandpass filter (Hz)\n",
    "# highcut = 1.0  # Upper bound of the bandpass filter (Hz)\n",
    "# fs = None  # Frame rate of the video (frames per second)\n",
    "# alpha = 20  # Amplification factor\n",
    "# eulerian_magnification(video_path, output_path, lowcut, highcut, fs, alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 7.03 GiB for an array with shape (3, 544, 960, 301) and data type complex128",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 59\u001b[0m\n\u001b[0;32m     56\u001b[0m spatial_pyramid \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(spatial_pyramid)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Apply temporal bandpass filter\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m filtered \u001b[38;5;241m=\u001b[39m \u001b[43mbandpass_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspatial_pyramid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhigh_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Amplify the signal\u001b[39;00m\n\u001b[0;32m     62\u001b[0m amplified \u001b[38;5;241m=\u001b[39m filtered \u001b[38;5;241m*\u001b[39m amplification_factor\n",
      "Cell \u001b[1;32mIn[11], line 49\u001b[0m, in \u001b[0;36mbandpass_filter\u001b[1;34m(buffer, low, high, fps)\u001b[0m\n\u001b[0;32m     47\u001b[0m mask \u001b[38;5;241m=\u001b[39m (frequencies \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m low) \u001b[38;5;241m&\u001b[39m (frequencies \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m high)\n\u001b[0;32m     48\u001b[0m fft[\u001b[38;5;241m~\u001b[39mmask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mifft\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreal\n",
      "File \u001b[1;32mf:\\python\\conda-envs\\torchcv\\Lib\\site-packages\\numpy\\fft\\_pocketfft.py:316\u001b[0m, in \u001b[0;36mifft\u001b[1;34m(a, n, axis, norm)\u001b[0m\n\u001b[0;32m    314\u001b[0m     n \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mshape[axis]\n\u001b[0;32m    315\u001b[0m inv_norm \u001b[38;5;241m=\u001b[39m _get_backward_norm(n, norm)\n\u001b[1;32m--> 316\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43m_raw_fft\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minv_norm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mf:\\python\\conda-envs\\torchcv\\Lib\\site-packages\\numpy\\fft\\_pocketfft.py:73\u001b[0m, in \u001b[0;36m_raw_fft\u001b[1;34m(a, n, axis, is_real, is_forward, inv_norm)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     a \u001b[38;5;241m=\u001b[39m swapaxes(a, axis, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 73\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mpfi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_real\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfct\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     r \u001b[38;5;241m=\u001b[39m swapaxes(r, axis, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 7.03 GiB for an array with shape (3, 544, 960, 301) and data type complex128"
     ]
    }
   ],
   "source": [
    "# # second code\n",
    "\n",
    "# # Load video\n",
    "# video = cv2.VideoCapture(\"tests/baby.mp4\")\n",
    "# fps = video.get(cv2.CAP_PROP_FPS)\n",
    "# frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "# width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "# height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# # Parameters for EVM\n",
    "# low_freq = 0.4  # Low-frequency bound (Hz)\n",
    "# high_freq = 3.0  # High-frequency bound (Hz)\n",
    "# amplification_factor = 50\n",
    "# pyramid_levels = 4  # For spatial filtering\n",
    "\n",
    "# # Functions for spatial processing\n",
    "# def build_laplacian_pyramid(frame, levels):\n",
    "#     pyramid = [frame]\n",
    "#     for _ in range(levels):\n",
    "#         frame = cv2.pyrDown(frame)\n",
    "#         pyramid.append(frame)\n",
    "#     return pyramid\n",
    "\n",
    "# def reconstruct_laplacian_pyramid(pyramid):\n",
    "#     current = pyramid[-1]\n",
    "#     for level in reversed(pyramid[:-1]):\n",
    "#         upsampled = cv2.pyrUp(current, dstsize=(level.shape[1], level.shape[0]))\n",
    "#         current = cv2.add(level, upsampled)\n",
    "#     return current\n",
    "\n",
    "# # Create video buffer\n",
    "# video_buffer = []\n",
    "# while True:\n",
    "#     ret, frame = video.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "#     frame = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)  # Use LAB for better color filtering\n",
    "#     video_buffer.append(frame)\n",
    "\n",
    "# video_buffer = np.array(video_buffer)\n",
    "# video.release()\n",
    "\n",
    "# # Temporal bandpass filtering\n",
    "# def bandpass_filter(buffer, low, high, fps):\n",
    "#     fft = np.fft.fft(buffer, axis=0)\n",
    "#     frequencies = np.fft.fftfreq(buffer.shape[0], d=1/fps)\n",
    "#     mask = (frequencies >= low) & (frequencies <= high)\n",
    "#     fft[~mask] = 0\n",
    "#     return np.fft.ifft(fft, axis=0).real\n",
    "\n",
    "# # Process each pyramid level\n",
    "# output_video = []\n",
    "# for level in range(pyramid_levels):\n",
    "#     # Extract spatial level\n",
    "#     spatial_pyramid = [build_laplacian_pyramid(frame, pyramid_levels)[level] for frame in video_buffer]\n",
    "#     spatial_pyramid = np.array(spatial_pyramid)\n",
    "\n",
    "#     # Apply temporal bandpass filter\n",
    "#     filtered = bandpass_filter(spatial_pyramid, low_freq, high_freq, fps)\n",
    "\n",
    "#     # Amplify the signal\n",
    "#     amplified = filtered * amplification_factor\n",
    "\n",
    "#     # Reconstruct the pyramid and add to original\n",
    "#     for i in range(len(video_buffer)):\n",
    "#         reconstructed = reconstruct_laplacian_pyramid([amplified[i] if j == level else np.zeros_like(amplified[i]) \n",
    "#                                                        for j in range(pyramid_levels)])\n",
    "#         frame = cv2.cvtColor(video_buffer[i], cv2.COLOR_LAB2BGR)\n",
    "#         frame += reconstructed  # Add the amplified signal\n",
    "#         output_video.append(frame)\n",
    "\n",
    "# # Write output video\n",
    "# out = cv2.VideoWriter(\"tests/baby_output_video.avi\", cv2.VideoWriter_fourcc(*'XVID'), fps, (width, height))\n",
    "# for frame in output_video:\n",
    "#     out.write(np.clip(frame, 0, 255).astype(np.uint8))\n",
    "# out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
